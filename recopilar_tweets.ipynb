{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f285793",
   "metadata": {},
   "source": [
    "# Proyecto de análisis de sentimientos con Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f919c4",
   "metadata": {},
   "source": [
    "###  En este notebook se llevan a cabo los pasos necesarios para convertir un dataset de tweets en un conjunto de datos etiquetados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9346f",
   "metadata": {},
   "source": [
    "Comenzamos instalando la librería TextBlob que es la que utilizaremos en este proyecto. TextBlob es una biblioteca basada en NLTK que simplifica muchas tareas comunes de procesamiento del lenguaje natural, como extracción de entidades, análisis de sentimientos, traducción de idiomas, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aba0dc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: TextBlob in c:\\users\\anton\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from TextBlob) (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\anton\\anaconda3\\lib\\site-packages (from nltk>=3.1->TextBlob) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from nltk>=3.1->TextBlob) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\anton\\anaconda3\\lib\\site-packages (from nltk>=3.1->TextBlob) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anton\\anaconda3\\lib\\site-packages (from nltk>=3.1->TextBlob) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\anton\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->TextBlob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649299d8",
   "metadata": {},
   "source": [
    "También necesitaremos NLKT. \n",
    "+ nltk: NLTK (Natural Language Toolkit) es una biblioteca de procesamiento del lenguaje natural en Python. Ofrece una amplia gama de herramientas y recursos para el análisis de texto, como tokenización, lematización, etiquetado gramatical, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a0c23e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement nlkt (from versions: none)\n",
      "ERROR: No matching distribution found for nlkt\n"
     ]
    }
   ],
   "source": [
    "pip install nlkt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c442c858",
   "metadata": {},
   "source": [
    "Importamos también módulos y librerías que serán necesarios para el desarrollo del proyecto.\n",
    "+ csv: Este módulo proporciona funcionalidades para leer y escribir archivos CSV.\n",
    "+ stopwords: Es un módulo específico de NLTK que proporciona una lista de palabras comunes que se consideran irrelevantes en el procesamiento de texto.\n",
    "+ string: Este módulo proporciona una serie de constantes y funciones relacionadas con cadenas de caracteres. \n",
    "+ re: El módulo re proporciona funciones para trabajar con expresiones regulares en Python.\n",
    "+ pandas: Pandas es una biblioteca popular para el análisis y manipulación de datos en Python. Proporciona estructuras de datos de alto rendimiento y fáciles de usar, como DataFrames, que permiten realizar operaciones eficientes en datos tabulares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11091a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import nltk\n",
    "from nltk .corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk import wordnet\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdce4aa",
   "metadata": {},
   "source": [
    "Hemos recopilado 1000 tweets del siguiente [dataset.](https://www.kaggle.com/datasets/kazanova/sentiment140?resource=download) Hemos ignorado las etiquetas preexistentes en este conjunto de datos y hemos procedido a etiquetarlo por nuestra cuenta.\n",
    "\n",
    "Guardamos los tweets en **tweets.csv**\n",
    "\n",
    "Los tweets se encontraban en un formato peculiar y presentaban una gran cantidad de caracteres ';'.\n",
    "Hemos creado la siguiente función para eliminar estos caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05a03964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_punto_coma(archivo_csv, archivo_salida):\n",
    "    with open(archivo_csv, 'r') as archivo_entrada, open(archivo_salida, 'w', newline='') as archivo_salida:\n",
    "        lector_csv = csv.reader(archivo_entrada)\n",
    "        escritor_csv = csv.writer(archivo_salida)\n",
    "\n",
    "        for fila in lector_csv:\n",
    "            fila_sin_punto_coma = [re.sub(r';', '', columna) for columna in fila]\n",
    "            escritor_csv.writerow(fila_sin_punto_coma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98fd0dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "eliminar_punto_coma('tweets.csv', 'tweets2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b70607",
   "metadata": {},
   "source": [
    "Almacenamos el nuevo formato de los tweets en **tweets2.csv**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362beed3",
   "metadata": {},
   "source": [
    "Generamos un DataFrame a partir de **tweets2.csv**. Esto permite manipular y analizar los datos de manera más conveniente utilizando las funcionalidades proporcionadas por la biblioteca pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ff44a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spring break in plain city... it's snowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I just re-pierced my ears</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@caregiving I couldn't bear to watch it.  And ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  is upset that he can't update his Facebook by ...\n",
       "1  @Kenichan I dived many times for the ball. Man...\n",
       "2    my whole body feels itchy and like its on fire \n",
       "3                      @Kwesidei not the whole crew \n",
       "4                                        Need a hug \n",
       "5               @Tatiana_K nope they didn't have it \n",
       "6                          @twittera que me muera ? \n",
       "7        spring break in plain city... it's snowing \n",
       "8                         I just re-pierced my ears \n",
       "9  @caregiving I couldn't bear to watch it.  And ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tweets2.csv', header=None, names=['text'], on_bad_lines='skip', encoding= 'unicode_escape')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1fc0fc",
   "metadata": {},
   "source": [
    "Creamos la función **limpiar_texto** que toma los tweets y aplica una serie de pasos de limpieza y procesamiento, incluyendo la eliminación de menciones, RTs, hashtags y enlaces, eliminación de signos de puntuación, eliminación de stopwords y lematización de palabras. El resultado final son unos tweets limpios y procesados listos para su posterior análisis o uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7857041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_texto(text):  \n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    text = str(text)\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', ' ', text) #Elimina las menciones\n",
    "    text = re.sub(r'RT[|\\s]', ' ', text) # Elimina los RTs\n",
    "    text = re.sub(r'#', ' ', text) #Elimina los hashtags\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', ' ', text) #Elimina los enlaces\n",
    "\n",
    "    pattern = r'''(?x)                 # Activa la opcion que permite expresiones regulares\n",
    "               (?:[A-Z]\\.)+            # abreviaturas\n",
    "               | \\w+(?:-\\w+)*          # Palabras con guiones externos que pueden ser opcionales\n",
    "               | \\$?\\d+(?:\\.\\d+)?%?    # Monedas y porcentajes\n",
    "               | \\.\\.\\.                # Elipsis\n",
    "              | [][.,;\"'?():-_`]       #Tokens separados\n",
    "               '''\n",
    "    words = nltk.regexp_tokenize(text, pattern)\n",
    "    delete_punt = re.compile('[%s]' % re.escape(string.punctuation)) # Elimina signos de puntuacion\n",
    "    stripped = [delete_punt.sub('', w) for w in words]\n",
    "    delete_stopwords = [w for w in stripped if  w.lower() not in stopWords] # Elimina las stopwords\n",
    "    lemmatized_words = [lemmatizer.lemmatize(w) for w in delete_stopwords]\n",
    "\n",
    "    return (\" \".join(lemmatized_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989f0d2b",
   "metadata": {},
   "source": [
    "Añadimos al DataFrame una columna con los tweets transformados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37350697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tweets_transform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset  update Facebook texting  might cry resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dived many time ball  Managed save 50 rest go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Need a hug</td>\n",
       "      <td>Need hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>@lisaholmes you can buy my fiances duplex in T...</td>\n",
       "      <td>buy fiance duplex Terwillegar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>@apleaforaaron i could really eat some cheese ...</td>\n",
       "      <td>could really eat cheese hankering austrian smo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>@ddlovato I am so FUCKING jealous of you girl....</td>\n",
       "      <td>FUCKING jealous girl  fun though xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>@ThaStevieG my bunnys name was Lucy  you can g...</td>\n",
       "      <td>bunny name Lucy go ahead guess named lmao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>@pixelpipe any updates for iPhone OS 3.0 yet? ...</td>\n",
       "      <td>update iPhone OS 3  0 yet  miss guy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>774 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    is upset that he can't update his Facebook by ...   \n",
       "1    @Kenichan I dived many times for the ball. Man...   \n",
       "2      my whole body feels itchy and like its on fire    \n",
       "3                        @Kwesidei not the whole crew    \n",
       "4                                          Need a hug    \n",
       "..                                                 ...   \n",
       "769  @lisaholmes you can buy my fiances duplex in T...   \n",
       "770  @apleaforaaron i could really eat some cheese ...   \n",
       "771  @ddlovato I am so FUCKING jealous of you girl....   \n",
       "772  @ThaStevieG my bunnys name was Lucy  you can g...   \n",
       "773  @pixelpipe any updates for iPhone OS 3.0 yet? ...   \n",
       "\n",
       "                                      tweets_transform  \n",
       "0    upset  update Facebook texting  might cry resu...  \n",
       "1    dived many time ball  Managed save 50 rest go ...  \n",
       "2                      whole body feel itchy like fire  \n",
       "3                                           whole crew  \n",
       "4                                             Need hug  \n",
       "..                                                 ...  \n",
       "769                      buy fiance duplex Terwillegar  \n",
       "770  could really eat cheese hankering austrian smo...  \n",
       "771               FUCKING jealous girl  fun though xxx  \n",
       "772          bunny name Lucy go ahead guess named lmao  \n",
       "773                update iPhone OS 3  0 yet  miss guy  \n",
       "\n",
       "[774 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweets_transform'] = df['text'].apply(limpiar_texto)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d08887",
   "metadata": {},
   "source": [
    "Creamos la función **analisis_sentimiento**, que utiliza la biblioteca TextBlob para realizar un análisis de sentimiento en un tweet proporcionado. El análisis de sentimiento calcula la polaridad del tweet, que oscila entre -1 y 1. Un valor cercano a 1 indica un sentimiento positivo, un valor cercano a -1 indica un sentimiento negativo, y un valor cercano a 0 indica un sentimiento neutro. La función toma el tweet como entrada, lo convierte en una cadena, utiliza TextBlob para realizar el análisis de sentimiento y devuelve el valor de polaridad correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13ddcdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisis_sentimiento(text):\n",
    "  text = str(text)\n",
    "  if text != '':\n",
    "    analisis = TextBlob(text) \n",
    "    analisis = analisis.sentiment\n",
    "    sentiment = analisis.polarity\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fb79be",
   "metadata": {},
   "source": [
    "Añadimos al DataFrame una columna con la polaridad de los tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a175f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tweets_transform</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset  update Facebook texting  might cry resu...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dived many time ball  Managed save 50 rest go ...</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>whole crew</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Need a hug</td>\n",
       "      <td>Need hug</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>@lisaholmes you can buy my fiances duplex in T...</td>\n",
       "      <td>buy fiance duplex Terwillegar</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>@apleaforaaron i could really eat some cheese ...</td>\n",
       "      <td>could really eat cheese hankering austrian smo...</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>@ddlovato I am so FUCKING jealous of you girl....</td>\n",
       "      <td>FUCKING jealous girl  fun though xxx</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>@ThaStevieG my bunnys name was Lucy  you can g...</td>\n",
       "      <td>bunny name Lucy go ahead guess named lmao</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>@pixelpipe any updates for iPhone OS 3.0 yet? ...</td>\n",
       "      <td>update iPhone OS 3  0 yet  miss guy</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>774 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    is upset that he can't update his Facebook by ...   \n",
       "1    @Kenichan I dived many times for the ball. Man...   \n",
       "2      my whole body feels itchy and like its on fire    \n",
       "3                        @Kwesidei not the whole crew    \n",
       "4                                          Need a hug    \n",
       "..                                                 ...   \n",
       "769  @lisaholmes you can buy my fiances duplex in T...   \n",
       "770  @apleaforaaron i could really eat some cheese ...   \n",
       "771  @ddlovato I am so FUCKING jealous of you girl....   \n",
       "772  @ThaStevieG my bunnys name was Lucy  you can g...   \n",
       "773  @pixelpipe any updates for iPhone OS 3.0 yet? ...   \n",
       "\n",
       "                                      tweets_transform  polarity  \n",
       "0    upset  update Facebook texting  might cry resu...      0.00  \n",
       "1    dived many time ball  Managed save 50 rest go ...      0.50  \n",
       "2                      whole body feel itchy like fire      0.20  \n",
       "3                                           whole crew      0.20  \n",
       "4                                             Need hug      0.00  \n",
       "..                                                 ...       ...  \n",
       "769                      buy fiance duplex Terwillegar      0.00  \n",
       "770  could really eat cheese hankering austrian smo...      0.20  \n",
       "771               FUCKING jealous girl  fun though xxx     -0.15  \n",
       "772          bunny name Lucy go ahead guess named lmao      0.60  \n",
       "773                update iPhone OS 3  0 yet  miss guy      0.00  \n",
       "\n",
       "[774 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['polarity'] = df['tweets_transform'].apply(analisis_sentimiento)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9a6c1e",
   "metadata": {},
   "source": [
    "Guardamos los tweets con las nuevas columnas en **tweets_polarizados.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb3e7602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tweets_transform</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset  update Facebook texting  might cry resu...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dived many time ball  Managed save 50 rest go ...</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>whole crew</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Need a hug</td>\n",
       "      <td>Need hug</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>@lisaholmes you can buy my fiances duplex in T...</td>\n",
       "      <td>buy fiance duplex Terwillegar</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>@apleaforaaron i could really eat some cheese ...</td>\n",
       "      <td>could really eat cheese hankering austrian smo...</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>@ddlovato I am so FUCKING jealous of you girl....</td>\n",
       "      <td>FUCKING jealous girl  fun though xxx</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>@ThaStevieG my bunnys name was Lucy  you can g...</td>\n",
       "      <td>bunny name Lucy go ahead guess named lmao</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>@pixelpipe any updates for iPhone OS 3.0 yet? ...</td>\n",
       "      <td>update iPhone OS 3  0 yet  miss guy</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>774 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    is upset that he can't update his Facebook by ...   \n",
       "1    @Kenichan I dived many times for the ball. Man...   \n",
       "2      my whole body feels itchy and like its on fire    \n",
       "3                        @Kwesidei not the whole crew    \n",
       "4                                          Need a hug    \n",
       "..                                                 ...   \n",
       "769  @lisaholmes you can buy my fiances duplex in T...   \n",
       "770  @apleaforaaron i could really eat some cheese ...   \n",
       "771  @ddlovato I am so FUCKING jealous of you girl....   \n",
       "772  @ThaStevieG my bunnys name was Lucy  you can g...   \n",
       "773  @pixelpipe any updates for iPhone OS 3.0 yet? ...   \n",
       "\n",
       "                                      tweets_transform  polarity  \n",
       "0    upset  update Facebook texting  might cry resu...      0.00  \n",
       "1    dived many time ball  Managed save 50 rest go ...      0.50  \n",
       "2                      whole body feel itchy like fire      0.20  \n",
       "3                                           whole crew      0.20  \n",
       "4                                             Need hug      0.00  \n",
       "..                                                 ...       ...  \n",
       "769                      buy fiance duplex Terwillegar      0.00  \n",
       "770  could really eat cheese hankering austrian smo...      0.20  \n",
       "771               FUCKING jealous girl  fun though xxx     -0.15  \n",
       "772          bunny name Lucy go ahead guess named lmao      0.60  \n",
       "773                update iPhone OS 3  0 yet  miss guy      0.00  \n",
       "\n",
       "[774 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('tweets_polarizados.csv', sep=',', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccfc383",
   "metadata": {},
   "source": [
    "Para asignar una etiqueta correspondiente al sentimiento de cada tweet, dividimos el rango de polaridad, que va desde -1 hasta 1, en cinco subrangos iguales. De esta manera, podemos categorizar cada tweet según su sentimiento y asignarle la etiqueta adecuada. Guardamos los tweets etiquetados en **tweets_etiquetados.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a880faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rangos = [(-1, -0.6), (-0.6, -0.2), (-0.2, 0.2), (0.2, 0.6), (0.6, 1)]\n",
    "etiquetas = ['Hater', 'Molesto', 'Neutro', 'Contento', 'Muy Feliz']\n",
    "\n",
    "data = []\n",
    "with open('tweets_polarizados.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "        \n",
    "with open('tweets_etiquetados.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Iterar sobre los datos y asignar las etiquetas correspondientes\n",
    "    for row in data:\n",
    "        try:\n",
    "            value = float(row[-1])  # Convertir a valor numérico\n",
    "            for i, (start, end) in enumerate(rangos):\n",
    "                if start <= value < end:\n",
    "                    row[-1] = etiquetas[i]\n",
    "                    break\n",
    "        except ValueError:\n",
    "            # Manejo de excepción para valores no numéricos\n",
    "            row[-1] = 'etiqueta'\n",
    "\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b67ae8",
   "metadata": {},
   "source": [
    "Durante el proceso de polarización, algunos tweets no han recibido una asignación de valor. Por lo tanto, tendremos tweets que no han sido etiquetados y que deberemos eliminar. En primer lugar, verificamos la cantidad de tweets inválidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a37ac4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas no válidas: 17\n"
     ]
    }
   ],
   "source": [
    "with open('tweets_etiquetados.csv', 'r') as archivo_csv:\n",
    "    lector_csv = csv.reader(archivo_csv)\n",
    "\n",
    "    # Inicializa el contador de filas no válidas\n",
    "    contador_filas_no_validas = 0\n",
    "\n",
    "    # Itera sobre cada fila del archivo CSV\n",
    "    for fila in lector_csv:\n",
    "        # Obtén el último valor de la fila\n",
    "        ultimo_valor = fila[-1]\n",
    "\n",
    "        # Verifica si el último valor no está en la lista de valores válidos\n",
    "        valores_validos = ['Hater', 'Molesto', 'Neutro', 'Contento', 'Muy Feliz']\n",
    "        if ultimo_valor not in valores_validos:\n",
    "            contador_filas_no_validas += 1\n",
    "\n",
    "# Imprime el resultado\n",
    "print(f\"Número de filas no válidas: {contador_filas_no_validas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d45827e",
   "metadata": {},
   "source": [
    "Dado que la cantidad de tweets inválidos es baja, procedemos a eliminarlos. Y guardamos los tweets en **tweets_etiquetados_bien.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a7e94b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar filas incorrectas\n",
    "with open('tweets_etiquetados.csv', 'r') as archivo_entrada, open('tweets_etiquetados_bien.csv', 'w', newline='') as archivo_salida:\n",
    "    lector_csv = csv.reader(archivo_entrada)\n",
    "    escritor_csv = csv.writer(archivo_salida)\n",
    "\n",
    "    # Lee la primera fila y la escribe en el archivo de salida sin cambios\n",
    "    primera_fila = next(lector_csv)\n",
    "    escritor_csv.writerow(primera_fila)\n",
    "\n",
    "    # Itera sobre cada fila del archivo de entrada\n",
    "    for fila in lector_csv:\n",
    "        # Obtén el último valor de la fila\n",
    "        ultimo_valor = fila[-1]\n",
    "\n",
    "        # Verifica si el último valor está en la lista de valores válidos\n",
    "        valores_validos = ['Hater', 'Molesto', 'Neutro', 'Contento', 'Muy Feliz']\n",
    "        if ultimo_valor in valores_validos:\n",
    "            # Escribe la fila en el archivo de salida\n",
    "            escritor_csv.writerow(fila)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9190b3",
   "metadata": {},
   "source": [
    "# Validación y entranimento de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "495592b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_original</th>\n",
       "      <th>tweet_transformado</th>\n",
       "      <th>etiqueta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset  update Facebook texting  might cry resu...</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dived many time ball  Managed save 50 rest go ...</td>\n",
       "      <td>Contento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "      <td>Contento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>whole crew</td>\n",
       "      <td>Contento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Need a hug</td>\n",
       "      <td>Need hug</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "      <td>K nope</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "      <td>que muera</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spring break in plain city... it's snowing</td>\n",
       "      <td>spring break plain city   snowing</td>\n",
       "      <td>Molesto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I just re-pierced my ears</td>\n",
       "      <td>repierced ear</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@caregiving I couldn't bear to watch it.  And ...</td>\n",
       "      <td>bear watch  thought UA loss embarrassing</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      tweet_original  \\\n",
       "0  is upset that he can't update his Facebook by ...   \n",
       "1  @Kenichan I dived many times for the ball. Man...   \n",
       "2    my whole body feels itchy and like its on fire    \n",
       "3                      @Kwesidei not the whole crew    \n",
       "4                                        Need a hug    \n",
       "5               @Tatiana_K nope they didn't have it    \n",
       "6                          @twittera que me muera ?    \n",
       "7        spring break in plain city... it's snowing    \n",
       "8                         I just re-pierced my ears    \n",
       "9  @caregiving I couldn't bear to watch it.  And ...   \n",
       "\n",
       "                                  tweet_transformado  etiqueta  \n",
       "0  upset  update Facebook texting  might cry resu...    Neutro  \n",
       "1  dived many time ball  Managed save 50 rest go ...  Contento  \n",
       "2                    whole body feel itchy like fire  Contento  \n",
       "3                                         whole crew  Contento  \n",
       "4                                           Need hug    Neutro  \n",
       "5                                            K nope     Neutro  \n",
       "6                                         que muera     Neutro  \n",
       "7                  spring break plain city   snowing   Molesto  \n",
       "8                                      repierced ear    Neutro  \n",
       "9      bear watch  thought UA loss embarrassing         Neutro  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('tweets_etiquetados_bien.csv', skiprows=1, names=['tweet_original', 'tweet_transformado', 'etiqueta'], encoding= 'unicode_escape')\n",
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2a931974",
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos = tweets['tweet_transformado']  # selección de la columna de atributos\n",
    "objetivo = tweets['etiqueta']  # selección de la columna objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b6705ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = TfidfVectorizer()\n",
    "atributo = vector.fit_transform(atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9a54aafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_entrenamiento, atributos_test, objetivo_entrenamiento, objetivo_test = train_test_split(atributo, objetivo, test_size=.33, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace0890",
   "metadata": {},
   "source": [
    "## Validación de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bef83f8",
   "metadata": {},
   "source": [
    "En esta sección validaremos la predección de los 3 modelos usados que son: \n",
    "\n",
    "        -Naive Bayes\n",
    "        \n",
    "        -Árboles de decisión\n",
    "        \n",
    "        -KNN\n",
    "\n",
    "Para realizar la validación utilizaremos la técnica de Validacion Cruzada de k iteraciones. En nuestro caso solo serán 4 iteraciones. Además, nos ayudaremos de la libreria \"model_selection\" de \"sklearn\" utilizando el método \"cross_val_score\" el cual calculará la predicción de cada modelo en cada iteración."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e4868",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "af34b08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de la iteración 1: 56.84%\n",
      "Precisión de la iteración 2: 56.84%\n",
      "Precisión de la iteración 3: 58.20%\n",
      "Precisión de la iteración 4: 57.67%\n",
      "Precisión media: 57.39%\n"
     ]
    }
   ],
   "source": [
    "modelo1 = MultinomialNB()\n",
    "precisiones1 = cross_val_score(modelo1, atributo, objetivo, cv=4)\n",
    "\n",
    "# Imprime los resultados de cada iteración\n",
    "for i, score in enumerate(precisiones1):\n",
    "    print(\"Precisión de la iteración {}: {:.2f}%\".format(i+1, score * 100))\n",
    "\n",
    "# Imprime la precisión media de todas las iteraciones\n",
    "precision_total = precisiones1.mean()\n",
    "print(\"Precisión media: {:.2f}%\".format(precision_total * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f8363",
   "metadata": {},
   "source": [
    "### Árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "079428d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de la iteración 1: 62.11%\n",
      "Precisión de la iteración 2: 61.05%\n",
      "Precisión de la iteración 3: 61.90%\n",
      "Precisión de la iteración 4: 58.73%\n",
      "Precisión media: 60.95%\n"
     ]
    }
   ],
   "source": [
    "modelo2 = DecisionTreeClassifier(\n",
    "    max_depth=5,  # máxima profundidad del árbol\n",
    "    random_state=54321  # semilla aleatoria, para que el código sea reproducible\n",
    ")\n",
    "\n",
    "precisiones2 = cross_val_score(modelo2, atributo, objetivo, cv=4)\n",
    "\n",
    "# Imprime los resultados de cada iteración\n",
    "for i, score in enumerate(precisiones2):\n",
    "    print(\"Precisión de la iteración {}: {:.2f}%\".format(i+1, score * 100))\n",
    "\n",
    "# Imprime la precisión media de todas las iteraciones\n",
    "precision_total2 = precisiones2.mean()\n",
    "print(\"Precisión media: {:.2f}%\".format(precision_total2 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cb19d6",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "015fee98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de la iteración 1: 58.42%\n",
      "Precisión de la iteración 2: 60.00%\n",
      "Precisión de la iteración 3: 58.73%\n",
      "Precisión de la iteración 4: 59.79%\n",
      "Precisión media: 59.23%\n"
     ]
    }
   ],
   "source": [
    "modelo3 = neighbors.KNeighborsClassifier(\n",
    "    n_neighbors=55,  # Número de vecinos a considerar\n",
    ")\n",
    "\n",
    "precision3 = cross_val_score(modelo3, atributo, objetivo, cv=4)\n",
    "\n",
    "# Imprime los resultados de cada iteración\n",
    "for i, score in enumerate(precision3):\n",
    "    print(\"Precisión de la iteración {}: {:.2f}%\".format(i+1, score * 100))\n",
    "\n",
    "# Imprime la precisión media de todas las iteraciones\n",
    "precision_total3 = precision3.mean()\n",
    "print(\"Precisión media: {:.2f}%\".format(precision_total3 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564a41f0",
   "metadata": {},
   "source": [
    "Como se puede observar, el modelo que presenta mejores prestaciones el de árboles de decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5639dc",
   "metadata": {},
   "source": [
    "## Predicción del conjunto de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c402cbd",
   "metadata": {},
   "source": [
    "Debido a que como hemos comentado antes, el mejor modelo en nuestro caso es el de \"Árboles de decisión\" por lo cual será el que usaremos para realizar la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "37e2e681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=5, random_state=54321)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=5, random_state=54321)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, random_state=54321)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasif_CART = DecisionTreeClassifier(\n",
    "    max_depth=5,  # máxima profundidad del árbol\n",
    "    random_state=54321  # semilla aleatoria, para que el código sea reproducible\n",
    ")\n",
    "clasif_CART.fit(atributos_entrenamiento, objetivo_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "08c3b99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neutro' 'Neutro' 'Muy Feliz' 'Neutro' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Molesto' 'Neutro' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Contento' 'Neutro' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Neutro' 'Muy Feliz' 'Neutro' 'Neutro' 'Neutro' 'Contento' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Contento' 'Neutro' 'Neutro' 'Contento'\n",
      " 'Contento' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Muy Feliz'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Molesto' 'Neutro'\n",
      " 'Neutro' 'Contento' 'Neutro' 'Neutro' 'Neutro' 'Molesto' 'Neutro'\n",
      " 'Muy Feliz' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Contento'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Contento' 'Neutro' 'Neutro' 'Muy Feliz' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Molesto' 'Neutro' 'Neutro' 'Neutro' 'Contento'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Muy Feliz' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Neutro' 'Contento' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Neutro' 'Contento' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Muy Feliz'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Muy Feliz'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Muy Feliz' 'Neutro' 'Neutro' 'Neutro' 'Muy Feliz' 'Contento' 'Muy Feliz'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Muy Feliz' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Muy Feliz' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Muy Feliz' 'Molesto' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Muy Feliz' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Muy Feliz'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Contento' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Muy Feliz' 'Neutro' 'Contento' 'Neutro'\n",
      " 'Neutro' 'Contento' 'Neutro' 'Contento' 'Neutro']\n"
     ]
    }
   ],
   "source": [
    "prediccion2 = clasif_CART.predict(atributos_test)\n",
    "print(prediccion2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "849f4454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 59.76%\n"
     ]
    }
   ],
   "source": [
    "precision = accuracy_score(objetivo_test, prediccion2)\n",
    "print(\"Precisión del modelo: {:.2f}%\".format(precision * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7984f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_comas_csv(archivo_entrada, archivo_salida):\n",
    "    with open(archivo_entrada, 'r') as f_in, open(archivo_salida, 'w') as f_out:\n",
    "        for linea in f_in:\n",
    "            nueva_linea = linea.replace(',', '')\n",
    "            f_out.write(nueva_linea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "59766ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "eliminar_comas_csv('andre_tate.csv', 'andre_tate_sin_comas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "48d79933",
   "metadata": {},
   "outputs": [],
   "source": [
    "eliminar_punto_coma('andre_tate.csv', 'andre_tate_correcto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "532c709a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_andre_tate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If The Matrix has proof of you doing something...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I would never kill myself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The level of stress I tolerate daily would be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neva catch mi with a fassy headset pon mi face...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You can give most men in life a guarantee of v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Matrix wants the best for you. The rules a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A lot of people comment on the fact I have a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The reason I work so hard when I make over 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hello @hollywills . You fooled absolutely nobo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alex Jones was right. But its not the frogs th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Linked in? Oh you mean... Gay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>First world country? You mean... Ghey?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>As a man you get to build your character. Life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>So Hunter Bidens laptop full of sexual crimes....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>It is not phobic to disagree with something. M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Shut up bigot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Being average means youve lost in a way which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>When youre an actual sexual predator this is h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I have a bunch of medical beliefs that I have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Plus the fact that my mind is at constant war ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The house record on the stairs machine was 189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I reserve the right to choose my company and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I am a storm far in the distance fed by the ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The BBC has been begging me for an interview d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dont take mindset tips from the happy man. Tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>If youre a redblooded male of honor and courag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A man can be in the worst position and all he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Download the Rumble app and subscribe to https...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>The level of stress and pressure I operate und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Educate her to the truth of my message. Make h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     tweet_andre_tate\n",
       "0   If The Matrix has proof of you doing something...\n",
       "1                           I would never kill myself\n",
       "2   The level of stress I tolerate daily would be ...\n",
       "3   Neva catch mi with a fassy headset pon mi face...\n",
       "4   You can give most men in life a guarantee of v...\n",
       "5   The Matrix wants the best for you. The rules a...\n",
       "6   A lot of people comment on the fact I have a s...\n",
       "7   The reason I work so hard when I make over 10 ...\n",
       "8   Hello @hollywills . You fooled absolutely nobo...\n",
       "9   Alex Jones was right. But its not the frogs th...\n",
       "10                     Linked in? Oh you mean... Gay?\n",
       "11             First world country? You mean... Ghey?\n",
       "12  As a man you get to build your character. Life...\n",
       "13  So Hunter Bidens laptop full of sexual crimes....\n",
       "14  It is not phobic to disagree with something. M...\n",
       "15                                     Shut up bigot.\n",
       "16  Being average means youve lost in a way which ...\n",
       "17  When youre an actual sexual predator this is h...\n",
       "18  I have a bunch of medical beliefs that I have ...\n",
       "19  Plus the fact that my mind is at constant war ...\n",
       "20  The house record on the stairs machine was 189...\n",
       "21  I reserve the right to choose my company and i...\n",
       "22  I am a storm far in the distance fed by the ev...\n",
       "23  The BBC has been begging me for an interview d...\n",
       "24  Dont take mindset tips from the happy man. Tak...\n",
       "25  If youre a redblooded male of honor and courag...\n",
       "26  A man can be in the worst position and all he ...\n",
       "27  Download the Rumble app and subscribe to https...\n",
       "28  The level of stress and pressure I operate und...\n",
       "29  Educate her to the truth of my message. Make h..."
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_andrew = pd.read_csv('andre_tate_correcto.csv', names=['tweet_andre_tate'], encoding= 'unicode_escape')\n",
    "tweets_andrew.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4a3b5950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_andre_tate</th>\n",
       "      <th>tweets_transform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If The Matrix has proof of you doing something...</td>\n",
       "      <td>Matrix proof something evidence charge punishm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I would never kill myself</td>\n",
       "      <td>would never kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The level of stress I tolerate daily would be ...</td>\n",
       "      <td>level stress tolerate daily would much 99 men ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neva catch mi with a fassy headset pon mi face...</td>\n",
       "      <td>Neva catch mi fassy headset pon mi face chek b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You can give most men in life a guarantee of v...</td>\n",
       "      <td>give men life guarantee victory literal cheat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Matrix wants the best for you. The rules a...</td>\n",
       "      <td>Matrix want best  rule made benefit people mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A lot of people comment on the fact I have a s...</td>\n",
       "      <td>lot people comment fact swollen face black eye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The reason I work so hard when I make over 10 ...</td>\n",
       "      <td>reason work hard make 10 million dollar month ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hello @hollywills . You fooled absolutely nobo...</td>\n",
       "      <td>Hello  fooled absolutely nobody guilty sexual ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alex Jones was right. But its not the frogs th...</td>\n",
       "      <td>Alex Jones right  frog want  kid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Linked in? Oh you mean... Gay?</td>\n",
       "      <td>Linked  Oh mean  Gay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>First world country? You mean... Ghey?</td>\n",
       "      <td>First world country  mean  Ghey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>As a man you get to build your character. Life...</td>\n",
       "      <td>man get build character  Life like video game ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>So Hunter Bidens laptop full of sexual crimes....</td>\n",
       "      <td>Hunter Bidens laptop full sexual crime  Photog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>It is not phobic to disagree with something. M...</td>\n",
       "      <td>phobic disagree something  Moral objection not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Shut up bigot.</td>\n",
       "      <td>Shut bigot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Being average means youve lost in a way which ...</td>\n",
       "      <td>average mean youve lost way similar others thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>When youre an actual sexual predator this is h...</td>\n",
       "      <td>youre actual sexual predator Matrix treat  Kid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I have a bunch of medical beliefs that I have ...</td>\n",
       "      <td>bunch medical belief zero proof  refuse read r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Plus the fact that my mind is at constant war ...</td>\n",
       "      <td>Plus fact mind constant war body reacts fact T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The house record on the stairs machine was 189...</td>\n",
       "      <td>house record stair machine 189 30 min set WAR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I reserve the right to choose my company and i...</td>\n",
       "      <td>reserve right choose company include believe b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I am a storm far in the distance fed by the ev...</td>\n",
       "      <td>storm far distance fed evaporating dream jealo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The BBC has been begging me for an interview d...</td>\n",
       "      <td>BBC begging interview daily since left jail  p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dont take mindset tips from the happy man. Tak...</td>\n",
       "      <td>Dont take mindset tip happy man  Take depresse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>If youre a redblooded male of honor and courag...</td>\n",
       "      <td>youre redblooded male honor courage  already a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A man can be in the worst position and all he ...</td>\n",
       "      <td>man worst position say Ill take care might fla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Download the Rumble app and subscribe to https...</td>\n",
       "      <td>Download Rumble app subscribe live notificatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>The level of stress and pressure I operate und...</td>\n",
       "      <td>level stress pressure operate would much 99  9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Educate her to the truth of my message. Make h...</td>\n",
       "      <td>Educate truth message  Make understand Matrix ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     tweet_andre_tate  \\\n",
       "0   If The Matrix has proof of you doing something...   \n",
       "1                           I would never kill myself   \n",
       "2   The level of stress I tolerate daily would be ...   \n",
       "3   Neva catch mi with a fassy headset pon mi face...   \n",
       "4   You can give most men in life a guarantee of v...   \n",
       "5   The Matrix wants the best for you. The rules a...   \n",
       "6   A lot of people comment on the fact I have a s...   \n",
       "7   The reason I work so hard when I make over 10 ...   \n",
       "8   Hello @hollywills . You fooled absolutely nobo...   \n",
       "9   Alex Jones was right. But its not the frogs th...   \n",
       "10                     Linked in? Oh you mean... Gay?   \n",
       "11             First world country? You mean... Ghey?   \n",
       "12  As a man you get to build your character. Life...   \n",
       "13  So Hunter Bidens laptop full of sexual crimes....   \n",
       "14  It is not phobic to disagree with something. M...   \n",
       "15                                     Shut up bigot.   \n",
       "16  Being average means youve lost in a way which ...   \n",
       "17  When youre an actual sexual predator this is h...   \n",
       "18  I have a bunch of medical beliefs that I have ...   \n",
       "19  Plus the fact that my mind is at constant war ...   \n",
       "20  The house record on the stairs machine was 189...   \n",
       "21  I reserve the right to choose my company and i...   \n",
       "22  I am a storm far in the distance fed by the ev...   \n",
       "23  The BBC has been begging me for an interview d...   \n",
       "24  Dont take mindset tips from the happy man. Tak...   \n",
       "25  If youre a redblooded male of honor and courag...   \n",
       "26  A man can be in the worst position and all he ...   \n",
       "27  Download the Rumble app and subscribe to https...   \n",
       "28  The level of stress and pressure I operate und...   \n",
       "29  Educate her to the truth of my message. Make h...   \n",
       "\n",
       "                                     tweets_transform  \n",
       "0   Matrix proof something evidence charge punishm...  \n",
       "1                                    would never kill  \n",
       "2   level stress tolerate daily would much 99 men ...  \n",
       "3   Neva catch mi fassy headset pon mi face chek b...  \n",
       "4   give men life guarantee victory literal cheat ...  \n",
       "5   Matrix want best  rule made benefit people mak...  \n",
       "6   lot people comment fact swollen face black eye...  \n",
       "7   reason work hard make 10 million dollar month ...  \n",
       "8   Hello  fooled absolutely nobody guilty sexual ...  \n",
       "9                   Alex Jones right  frog want  kid   \n",
       "10                              Linked  Oh mean  Gay   \n",
       "11                   First world country  mean  Ghey   \n",
       "12  man get build character  Life like video game ...  \n",
       "13  Hunter Bidens laptop full sexual crime  Photog...  \n",
       "14  phobic disagree something  Moral objection not...  \n",
       "15                                        Shut bigot   \n",
       "16  average mean youve lost way similar others thi...  \n",
       "17  youre actual sexual predator Matrix treat  Kid...  \n",
       "18  bunch medical belief zero proof  refuse read r...  \n",
       "19  Plus fact mind constant war body reacts fact T...  \n",
       "20  house record stair machine 189 30 min set WAR ...  \n",
       "21  reserve right choose company include believe b...  \n",
       "22  storm far distance fed evaporating dream jealo...  \n",
       "23  BBC begging interview daily since left jail  p...  \n",
       "24  Dont take mindset tip happy man  Take depresse...  \n",
       "25  youre redblooded male honor courage  already a...  \n",
       "26  man worst position say Ill take care might fla...  \n",
       "27  Download Rumble app subscribe live notificatio...  \n",
       "28  level stress pressure operate would much 99  9...  \n",
       "29  Educate truth message  Make understand Matrix ...  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_andrew['tweets_transform'] = tweets_andrew['tweet_andre_tate'].apply(limpiar_texto)\n",
    "tweets_andrew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fd1269a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_and = tweets_andrew['tweets_transform']\n",
    "vector_andrew = TfidfVectorizer()\n",
    "atributo_andrew = vector.transform(atributos_and)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "be55923d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Contento'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro'\n",
      " 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Neutro' 'Contento']\n"
     ]
    }
   ],
   "source": [
    "prediccion_andrew = clasif_CART.predict(atributo_andrew)\n",
    "print(prediccion_andrew)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
